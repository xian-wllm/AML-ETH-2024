{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tibo1.Lab3.utils import get_device\n",
    "from tibo1.Lab3.model import UNet\n",
    "import pickle\n",
    "import gzip\n",
    "from tqdm import tqdm"
   ],
   "id": "7666ad0d1fa233ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Submission Generation\n",
    "#### 1a. Load Preprocessed test data"
   ],
   "id": "ef99517a01e56dc1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load Preprocessed test data\n",
    "test = np.load('./tibo1/Lab3/out/preprocessed/test.npy', allow_pickle=True)\n",
    "print(test.shape)"
   ],
   "id": "2920e83cea8b5f58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:55:26.485819Z",
     "start_time": "2024-12-08T23:55:21.020774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_zipped_pickle(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Load test metadata\n",
    "test_data = load_zipped_pickle('./tibo1/Lab3/data/test.pkl')\n",
    "\n",
    "# Generate test frame names\n",
    "test_names = []\n",
    "for patient in tqdm(test_data, desc=\"Generating Test Names\"):\n",
    "    video_name = patient['name']\n",
    "    n_frames = patient['video'].shape[-1]\n",
    "    test_names.extend([f\"{video_name}_{frame}\" for frame in range(n_frames)])\n",
    "\n",
    "print(f\"Generated {len(test_names)} test frame names.\")\n",
    "assert len(test_names) == sum([p['video'].shape[-1] for p in test_data]), \"Mismatch between test frames and names.\"\n"
   ],
   "id": "e7f73acd696b21d7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Test Names: 100%|██████████| 20/20 [00:00<00:00, 51181.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1507 test frame names.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:55:53.376092Z",
     "start_time": "2024-12-08T23:55:52.494759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = get_device()\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# Load model\n",
    "model = UNet(n_channels=1, n_classes=1, bilinear=False)\n",
    "model_path = './tibo1/Lab3/out/checkpoints/best_model_epoch_1.pth'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Loaded model from {model_path}.\")\n"
   ],
   "id": "fd2b864e5679f503",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "Loaded model from ./tibo1/Lab3/out/checkpoints/best_model_epoch_1.pth.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Make predictions",
   "id": "62c26005e3cb8dec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:57:55.163640Z",
     "start_time": "2024-12-08T23:57:12.414550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = []\n",
    "\n",
    "for patient in tqdm(test, desc=\"Predicting test frames\"):\n",
    "    video_name = patient['name']\n",
    "    video_frames = patient['video']  # Extract the video frames from the dictionary\n",
    "\n",
    "    for frame_idx in range(video_frames.shape[-1]):  # Iterate over each frame in the video\n",
    "        # Extract and process the individual frame\n",
    "        video_frame = video_frames[..., frame_idx]\n",
    "        frame_tensor = torch.tensor(video_frame, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Predict mask for the frame\n",
    "            pred_mask = model(frame_tensor)\n",
    "            pred_mask = (pred_mask > 0.5).float().cpu().numpy().squeeze()\n",
    "\n",
    "        # Append prediction with the correct name\n",
    "        predictions.append((f\"{video_name}_{frame_idx}\", pred_mask))\n",
    "\n",
    "print(f\"Generated predictions for {len(predictions)} frames.\")"
   ],
   "id": "9d207d9d18d2e3b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting test frames: 100%|██████████| 20/20 [00:42<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated predictions for 4480 frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Format Predictions in Correct Format",
   "id": "50dee4770296dc52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T00:00:31.005954Z",
     "start_time": "2024-12-08T23:58:21.251613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sequences(arr):\n",
    "    \"\"\"\n",
    "    Extracts sequences of 1s from a flattened array for submission format.\n",
    "    \"\"\"\n",
    "    indices, lengths = [], []\n",
    "    in_sequence = False\n",
    "    start_idx = 0\n",
    "    for i, val in enumerate(arr):\n",
    "        if val == 1 and not in_sequence:\n",
    "            start_idx = i\n",
    "            in_sequence = True\n",
    "        elif val == 0 and in_sequence:\n",
    "            indices.append(start_idx)\n",
    "            lengths.append(i - start_idx)\n",
    "            in_sequence = False\n",
    "    if in_sequence:\n",
    "        indices.append(start_idx)\n",
    "        lengths.append(len(arr) - start_idx)\n",
    "    return indices, lengths\n",
    "\n",
    "\n",
    "ids = []\n",
    "values = []\n",
    "\n",
    "for name, mask in tqdm(predictions, desc=\"Formatting predictions\"):\n",
    "    flat_mask = mask.flatten()\n",
    "    indices, lengths = get_sequences(flat_mask)\n",
    "    for start, length in zip(indices, lengths):\n",
    "        ids.append(name)\n",
    "        values.append([start, length])\n"
   ],
   "id": "264f4ed0c3bdfee2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting predictions:  19%|█▉        | 868/4480 [02:09<08:59,  6.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_23201/2780915418.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdesc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Formatting predictions\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m     \u001B[0mflat_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m     \u001B[0mindices\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlengths\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_sequences\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflat_mask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlength\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlengths\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mids\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_23201/2780915418.py\u001B[0m in \u001B[0;36mget_sequences\u001B[0;34m(arr)\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mstart_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0mval\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0min_sequence\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m             \u001B[0mstart_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m             \u001B[0min_sequence\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T00:00:32.722997Z",
     "start_time": "2024-12-09T00:00:32.718036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Total predictions: {len(predictions)}\")\n",
    "for i in range(3):  # Print the first three predictions\n",
    "    print(predictions[i])"
   ],
   "id": "51ef1e5e311261eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 4480\n",
      "('E9AHVWGBUF_0', array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n",
      "('E9AHVWGBUF_1', array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n",
      "('E9AHVWGBUF_2', array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T00:00:34.148377Z",
     "start_time": "2024-12-09T00:00:34.144880Z"
    }
   },
   "cell_type": "code",
   "source": "print(pred_mask.max(), pred_mask.min())",
   "id": "5cc6bac7f86095fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Save Predictions",
   "id": "2d3e040c8807394c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    \"id\": ids,\n",
    "    \"value\": [str(value) for value in values]\n",
    "})\n",
    "\n",
    "submission_file = \"./tibo1/Lab3/out/1_submission_best_model_fine_tuned_epoch1.csv\"\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "print(f\"Submission saved to {submission_file}\")"
   ],
   "id": "c50d3c14e05d9ea5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T00:00:41.764847Z",
     "start_time": "2024-12-09T00:00:41.756492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "# Save some frames and their masks for debugging\n",
    "for i in range(3):  # Save first three frames\n",
    "    cv2.imwrite(f\"./tibo1/Lab3/debug/frame_{i}.png\", test[i] * 255)\n",
    "    cv2.imwrite(f\"./tibo1/Lab3/debug/pred_mask_{i}.png\", predictions[i][1] * 255)\n"
   ],
   "id": "75c3b8c9f1ddfba5",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_23201/4058978697.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Save some frames and their masks for debugging\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# Save first three frames\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"./tibo1/Lab3/debug/frame_{i}.png\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m255\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mcv2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"./tibo1/Lab3/debug/pred_mask_{i}.png\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m255\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for *: 'dict' and 'int'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T00:00:43.332632Z",
     "start_time": "2024-12-09T00:00:42.877452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, mask in predictions[:3]:  # Debug first three predictions\n",
    "    flat_mask = mask.flatten()\n",
    "    indices, lengths = get_sequences(flat_mask)\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Mask non-zero count: {np.count_nonzero(flat_mask)}\")\n",
    "    print(f\"Sequences (indices): {indices}\")\n",
    "    print(f\"Sequences (lengths): {lengths}\")\n"
   ],
   "id": "ca43729b7005db99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: E9AHVWGBUF_0\n",
      "Mask non-zero count: 0\n",
      "Sequences (indices): []\n",
      "Sequences (lengths): []\n",
      "Name: E9AHVWGBUF_1\n",
      "Mask non-zero count: 0\n",
      "Sequences (indices): []\n",
      "Sequences (lengths): []\n",
      "Name: E9AHVWGBUF_2\n",
      "Mask non-zero count: 0\n",
      "Sequences (indices): []\n",
      "Sequences (lengths): []\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T23:58:13.229587Z",
     "start_time": "2024-12-08T23:58:11.580388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load a training frame for debugging\n",
    "expert_X_train = np.load('./tibo1/Lab3/out/preprocessed/expert_X_train.npy')\n",
    "\n",
    "# Use a sample from the expert training data\n",
    "train_sample = expert_X_train[0]  # First preprocessed training image\n",
    "train_tensor = torch.tensor(train_sample, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "# Predict the mask\n",
    "with torch.no_grad():\n",
    "    train_pred_mask = model(train_tensor)\n",
    "    print(f\"Train Sample Prediction - Max: {train_pred_mask.max()}, Min: {train_pred_mask.min()}, Mean: {train_pred_mask.mean()}\")"
   ],
   "id": "21c8a8a12f1c1718",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sample Prediction - Max: 0.0, Min: 0.0, Mean: 0.0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36a3e122d81b8737"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
